{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start simple, Start linearly\n",
    "\n",
    "The program below will mark the first RL algorithm truly implemented in this project. As such, to see if I've got the basics down, I started with a simply linear policy to learn. The algorithm contains two main parts. \n",
    "\n",
    "* The first is to learn a surrogate dynamics model of the environment. I personally like to think of this as the agent's belief of how the environment behaves, so the term surrogate doesn't too appropriate. A GP model will be used, with a gaussian covariance kernel. \n",
    "\n",
    "* The second is to use this belief of the system to learn an optimal policy. As mentioned previously, a linear policy structure will be used. Furthermore, bayesian optimisation with expected improvement will be used to find the optimal policy values. \n",
    "\n",
    "Let's see how this goes. Fingers crossed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import gym\n",
    "import GPy\n",
    "import GPyOpt\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "import gympy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the libraries have been imported as above, the openai gym environment and the appropriate covariance kernels will need to be defined. The former of these can be carried out using the *setupEnvironment* function in the gympy library. This outputs the relevant input and observations arrays, as well as the rewards, action and prediction initial arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the environment: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-18 18:24:15,054] Making new env: Pendulum-v0\n"
     ]
    }
   ],
   "source": [
    "env, observations, inputsNumpy, observationsNumpy, rewardsNumpy, action, predictionPDF = gympy.setupEnvironment(defaultEnvironment = 'Pendulum-v0', whichVersion = 0)\n",
    "k_dynamics = GPy.kern.RBF(input_dim=4, variance=1., lengthscale=1.)\n",
    "k_rewards = GPy.kern.RBF(input_dim=3, variance=1., lengthscale=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now necessary to define the key features of the RL algorithm. These include the how the reward (or cost) will be caluculated, the structure of the policy, and finally the objective function that will be minimised. \n",
    "\n",
    "The first of these is how the reward will be calculated. The reward, as mentioned in the [previous notebook](Learning_3.ipynb), the reward is function of the current state and the goal state. For the present notebook, the reward is calculated as the sum of the geometric distances between the each of the current states and the goal states. Please note that since each of these will be $ \\geqslant \\: 0$, it is technically speaking a cost, rather than a reward. However, since the difference betweeen the two is merely a negative symbol, reward and cost will be used interchangebly. \n",
    "\n",
    "Since the present problem will use a linear policy, which is only applicable to a pendulum at very small angles away from equilibrium points, the agent will be punished for moving away by $1^0$ from the equilibrium angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateTotalReward(predictionPDF, goalState, totalReward):\n",
    "    predictionPDF[0,2] = predictionPDF[0,1]/8\n",
    "    if (abs(predictionPDF[0,0]) < np.cos(5*np.pi/180)) or (abs(predictionPDF[0,1]) > np.sin(5*np.pi/180)):\n",
    "        multiplier = 1000\n",
    "    else:\n",
    "        multiplier = 1\n",
    "    currentReward = multiplier*(np.sqrt(np.sum((predictionPDF-goalState)*(predictionPDF-goalState))))\n",
    "    totalReward = totalReward + currentReward\n",
    "    \n",
    "    return totalReward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The policy must now be defined in terms of its parameters. In this particular example, a linear policy was chosen, for simplicity. This will be of the form:\n",
    "\n",
    "$$ \\pi(s_t) = \\phi(s_t)^T \\mathbf{\\theta} + \\mathbf{b},$$\n",
    "\n",
    "where the basis functions in $\\phi$ are simply the state variables, and the vector $\\theta$ represents the weights. Thus the action will be selected by policy that looks like:\n",
    "\n",
    "$$ a_t = s_{t,1}\\theta_1 + s_{t,2}\\theta_2  +  s_{t,3}\\theta_3 + \\theta_4, $$\n",
    "\n",
    "since this particular problem has 3 state variables. Note that $\\theta_4$ is the sum of the vector $\\mathbf{b}$. The reinforcement learning problem now becomes one of finiding the values of $\\theta$ such that the cost defined earlier is minimised. \n",
    "\n",
    "A function is defined to return the action after following the equation above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def action_fromPolicy(policyParameters, bufferObservations_policy):\n",
    "    actionToTake_policy = 0\n",
    "    [r,c] = policyParameters.shape\n",
    "    for i in range(c):\n",
    "        if i < c-1:\n",
    "            actionToTake_policy = actionToTake_policy + (bufferObservations_policy[0,i] * policyParameters[0,i])\n",
    "        else:\n",
    "            actionToTake_policy = actionToTake_policy + policyParameters[0,i]\n",
    "    actionToTake_policy = 2 * ((9/8)*np.sin(actionToTake_policy) + (1/8)*np.sin(3*actionToTake_policy))         \n",
    "\n",
    "    return actionToTake_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the policy parameters that minimise the total reward is clearly an optimisation problem. As such the optimisation method that will be used for this particular notebook is Bayesian Optimisation using Expected Improvement. Simply put, this methods chooses the next test point based on the highest expected improvement from the current minimun point (for a minimising problem that is). Thusly, a good mix of exploration and exploitation can be utilised to find the global minimum given the state box.\n",
    "\n",
    "The python library GPyOpt will be utilised for this. This requires the definition of an objective function; this is function that is to be optimised. In the present work, this will be the mapping from the policyy parameters to the total reward. Since this is a model based RL algorithm, the GP model that was trained previously will be used to generate the total reward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def objectiveFunction(policyParameters):\n",
    "    thetaBound = np.array([np.pi*5*180,1])\n",
    "    thetaObservations = np.random.uniform(low=-thetaBound, high=thetaBound)\n",
    "\n",
    "    bufferObservations_policy = np.array([np.cos(thetaObservations[0]), np.sin(thetaObservations[0]), thetaObservations[1]])\n",
    "\n",
    "    bufferObservations_policy = np.reshape(bufferObservations_policy, ([1,3]))\n",
    "    bufferInputs_policy = np.zeros((1,4))\n",
    "    \n",
    "    totalIterations = 100\n",
    "    totalReward = 0\n",
    "    \n",
    "    goalState = np.array([1,0,0])\n",
    "\n",
    "    \n",
    "    actionToTake_policy = action_fromPolicy(policyParameters, bufferObservations_policy)\n",
    "    predictionPDF = bufferObservations_policy\n",
    "    \n",
    "    attempt = 1\n",
    "    for i in range(totalIterations):\n",
    "        \n",
    "#         if abs(actionToTake_policy) > 2:\n",
    "#             totalReward = totalReward + 1000\n",
    "        bufferActionToTake = np.array([actionToTake_policy])\n",
    "        bufferActionToTake = np.reshape(bufferActionToTake, ([1]))\n",
    "        bufferACtionToTake_toAppend = np.reshape(bufferActionToTake,([1,1]))\n",
    "        bufferInputs_policy = np.append(bufferActionToTake_toAppend, predictionPDF, axis = 1) \n",
    "\n",
    "#         predictionPDF = m_dynamics.predict(bufferInputs_policy)[0]\n",
    "        \n",
    "        predictionPDF, rewards, done, info = env.step(bufferActionToTake)\n",
    "        predictionPDF_actual = np.reshape(predictionPDF, ([1,3]))\n",
    "        predctionPDF_emulation = m_dynamics.predict(bufferInputs_policy)[0]\n",
    "        \n",
    "#         inputsNumpy, bufferInput = gympy.appendInputArray(inputsNumpy, bufferActionToTake_toAppend, predictionPDF, attempt)\n",
    "#         [observationsNumpy, bufferObservations] = gympy.appendObservationsArray(observationsNumpy, observations, attempt)\n",
    "        \n",
    "        totalReward = generateTotalReward(predictionPDF_actual, goalState, totalReward)\n",
    "        actionToTake_policy = action_fromPolicy(policyParameters, predictionPDF)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         env.setState(np.arccos(predictionPDF[0,0]), predictionPDF[0,2])\n",
    "#         env.render()\n",
    "#         if (abs(predictionPDF_actual[0,0]) < np.cos(5*np.pi/180)):\n",
    "#             break\n",
    "\n",
    "        \n",
    "\n",
    "#     m_dynamics = gympy.generateModel(inputsNumpy, observationsNumpy, k_dynamics)\n",
    "#     m_dynamics.optimize()\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    return totalReward\n",
    "\n",
    "def objectiveFunction_iterations(policyParameters):\n",
    "    thetaBound = np.array([np.pi*5*180,1])\n",
    "    thetaObservations = np.random.uniform(low=-thetaBound, high=thetaBound)\n",
    "\n",
    "    bufferObservations_policy = np.array([np.cos(thetaObservations[0]), np.sin(thetaObservations[0]), thetaObservations[1]])\n",
    "\n",
    "    bufferObservations_policy = np.reshape(bufferObservations_policy, ([1,3]))\n",
    "    bufferInputs_policy = np.zeros((1,4))\n",
    "    \n",
    "    totalIterations = 1000\n",
    "    totalReward = 0\n",
    "    counter = 1\n",
    "    \n",
    "    predictionPDF = env.reset(whichVersion=1)\n",
    "    predictionPDF = np.reshape(predictionPDF, ([1,3]))\n",
    "    actionToTake_policy = action_fromPolicy(policyParameters, predictionPDF)\n",
    "    \n",
    "    \n",
    "    \n",
    "    while abs(predictionPDF[0,0]) > np.cos(5*np.pi/180) and counter <= totalIterations:\n",
    "                \n",
    "        bufferActionToTake = np.array([actionToTake_policy])\n",
    "        bufferActionToTake = np.reshape(bufferActionToTake, ([1]))\n",
    "#         bufferActionToTake_toAppend = np.reshape(bufferActionToTake,([1,1]))\n",
    "#         bufferInputs_policy = np.append(bufferActionToTake_toAppend, predictionPDF, axis = 1) \n",
    "        \n",
    "        predictionPDF, rewards, done, info = env.step(bufferActionToTake)\n",
    "        predictionPDF = np.reshape(predictionPDF, ([1,3]))\n",
    "        actionToTake_policy = action_fromPolicy(policyParameters,predictionPDF)\n",
    "        \n",
    "        counter += 1\n",
    "    \n",
    "    \n",
    "    totalReward = (1 - (np.exp(-((counter - totalIterations)^2)/((totalIterations/1)^2))))\n",
    "    \n",
    "    return totalReward\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random policy is now created to start the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "policyBounds = np.array([1,1,1,10])\n",
    "policyParameters =  np.random.uniform(low = -policyBounds, high = policyBounds)\n",
    "policyParameters = np.reshape(policyParameters,([1,4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What follows now will be the RL loop. However, in order to explain the steps using markdown the first iteration will be carried out outside the loop. The remaining steps will be carried out within a loop without any remarks.\n",
    "\n",
    "Once the policy parameters have been chosen, they must be used on the actual system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for attempt in range(1000):\n",
    "    if attempt%200 == 0:\n",
    "        observations = env.reset(whichVersion=0)\n",
    "        \n",
    "    bufferObservations = np.reshape(observations, ([1,3]))\n",
    "    actionToTake = action_fromPolicy(policyParameters, bufferObservations)\n",
    "    actionToTake_random = env.action_space.sample()\n",
    "    \n",
    "    inputsNumpy, bufferInput = gympy.appendInputArray(inputsNumpy, actionToTake_random, observations, attempt)\n",
    "    \n",
    "    actionToTake = np.array([actionToTake])\n",
    "    \n",
    "    [observationsNumpy, bufferObservations] = gympy.appendObservationsArray(observationsNumpy, observations, attempt)\n",
    "    \n",
    "    observations, rewards, done, info = env.step(actionToTake_random)\n",
    "    \n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the data points that were recorded from this trial, the system will learn a model of how the environment behaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_dynamics = gympy.generateModel(inputsNumpy, observationsNumpy, k_dynamics)\n",
    "m_dynamics.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(inputsNumpy[:,0])\n",
    "plt.title('Actions')\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(inputsNumpy[:,1])\n",
    "plt.title('cos(angle)')\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(inputsNumpy[:,2])\n",
    "plt.title('sin(angle)')\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(inputsNumpy[:,3])\n",
    "print policyParameters\n",
    "plt.title('angle_dot')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the agent will attempt to optimise the parameters of the policy using this learned model as its belief of how the environment behave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bounds = [{'domain': (-1,1), 'name': 'var_1', 'type': 'continuous', 'dimensionality':3},\n",
    "         {'domain': (-10,10), 'name': 'var_4', 'type': 'continuous', 'dimensionality':1}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-18 19:20:23,293] initializing Y\n",
      "[2016-11-18 19:20:23,294] initializing inference method\n",
      "[2016-11-18 19:20:23,295] adding kernel and likelihood as parameters\n",
      "[2016-11-18 19:20:23,301] initializing Y\n",
      "[2016-11-18 19:20:23,302] initializing inference method\n",
      "[2016-11-18 19:20:23,302] adding kernel and likelihood as parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.]\n",
      "(5, 1)\n"
     ]
    }
   ],
   "source": [
    "myBopt = GPyOpt.methods.BayesianOptimization(f = objectiveFunction_iterations, domain = bounds, acquisition_type ='MPI', num_cores=4, verbosity=True)\n",
    "max_iter = 100              # evaluation budget\n",
    "myBopt.run_optimization(max_iter)   # run optimization\n",
    "print min(myBopt.Y)\n",
    "print myBopt.Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-18 19:16:31,750] initializing Y\n",
      "[2016-11-18 19:16:31,751] initializing inference method\n",
      "[2016-11-18 19:16:31,752] adding kernel and likelihood as parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8102.08392758]\n",
      "(5, 1)\n"
     ]
    }
   ],
   "source": [
    "max_iter = 100              # evaluation budget\n",
    "myBopt.run_optimization(max_iter)   # run optimization\n",
    "print min(myBopt.Y)\n",
    "print myBopt.Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the policy that produced to smallest long term cost, will be chosen, and will be used on the environment once more, which will then generate more data that will be added to the dynamics model to be optimised again. As such, the loop continues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.]\n",
      "[[ 0.526726   -0.6232747   0.16699651  1.18831694]]\n"
     ]
    }
   ],
   "source": [
    "policyParameters = myBopt.X[np.argmin(myBopt.Y)]\n",
    "print min(myBopt.Y)\n",
    "policyParameters = np.reshape(policyParameters, ([1,4]))\n",
    "print policyParameters \n",
    "\n",
    "# thetaBound = np.array([np.pi*5*180,1])\n",
    "\n",
    "# thetaObservations = np.random.uniform(low=-thetaBound, high=thetaBound)\n",
    "\n",
    "# bufferObservations_policy = np.array([np.cos(thetaObservations[0]), np.sin(thetaObservations[0]), thetaObservations[1]])\n",
    "\n",
    "# bufferObservations_policy = np.reshape(bufferObservations_policy, ([1,3]))\n",
    "# actionBuffer = action_fromPolicy(policyParameters, bufferObservations_policy)\n",
    "\n",
    "# predictionPDF = bufferObservations_policy\n",
    "# print predictionPDF\n",
    "# env.setState(np.arccos(predictionPDF[0,0]),predictionPDF[0,2]) \n",
    "# for i in range(100):\n",
    "#     bufferActionToTake = np.array([actionBuffer])\n",
    "#     bufferActionToTake = np.reshape(bufferActionToTake, ([1,1]))\n",
    "#     bufferInputs_policy = np.append(bufferActionToTake, predictionPDF,axis = 1)\n",
    "    \n",
    "#     predictionPDF = m_dynamics.predict(bufferInputs_policy)[0]\n",
    "    \n",
    "#     actionToTake_policy = action_fromPolicy(policyParameters, predictionPDF)\n",
    "    \n",
    "#     print predictionPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-18 18:58:07,264] initializing Y\n",
      "[2016-11-18 18:58:07,265] initializing inference method\n",
      "[2016-11-18 18:58:07,266] adding kernel and likelihood as parameters\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'bufferActionToTake_toAppend' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-bcc4e9ce0715>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0minitialX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicyParameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#     print initialX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mmyBopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPyOpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjectiveFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdomain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macquisition_type\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'MPI'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_cores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m              \u001b[0;31m# evaluation budget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mmyBopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_optimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# run optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/janith_p/anaconda2/lib/python2.7/site-packages/GPyOpt/methods/bayesian_optimization.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, domain, constrains, cost_withGradients, model_type, X, Y, initial_design_numdata, initial_design_type, acquisition_type, normalize_Y, exact_feval, acquisition_optimizer_type, model_update_interval, evaluator_type, batch_size, num_cores, verbosity, verbosity_model, bounds, maximize, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'At least one initial point is needed to start the optimization'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_design_chooser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;31m# --- CHOOSE the model type. If an instance of a GPyOpt model is passed (possibly user defined), it is used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/janith_p/anaconda2/lib/python2.7/site-packages/GPyOpt/methods/bayesian_optimization.pyc\u001b[0m in \u001b[0;36m_init_design_chooser\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_design\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_design_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_design_numdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0;31m# Case 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/janith_p/anaconda2/lib/python2.7/site-packages/GPyOpt/core/task/objective.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_procs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mf_evals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_evals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/janith_p/anaconda2/lib/python2.7/site-packages/GPyOpt/core/task/objective.pyc\u001b[0m in \u001b[0;36m_eval_func\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mrlt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mrlt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mf_evals\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf_evals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrlt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mcost_evals\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mst_time\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-c37121e56eb6>\u001b[0m in \u001b[0;36mobjectiveFunction\u001b[0;34m(policyParameters)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mbufferActionToTake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufferActionToTake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mbufferACtionToTake_toAppend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufferActionToTake\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mbufferInputs_policy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufferActionToTake_toAppend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictionPDF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#         predictionPDF = m_dynamics.predict(bufferInputs_policy)[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'bufferActionToTake_toAppend' is not defined"
     ]
    }
   ],
   "source": [
    "for iterations in range(5):\n",
    "    observations = env.reset(whichVersion = 1)\n",
    "    for attempt in range(201):\n",
    "        attempt = attempt + 1\n",
    "        bufferObservations = np.reshape(observations, ([1,3]))\n",
    "        actionToTake = action_fromPolicy(policyParameters, bufferObservations)\n",
    "\n",
    "        inputsNumpy, bufferInput = gympy.appendInputArray(inputsNumpy, actionToTake, observations, attempt)\n",
    "        actionToTake = np.array([actionToTake])\n",
    "\n",
    "        [observationsNumpy, bufferObservations] = gympy.appendObservationsArray(observationsNumpy, observations, attempt)\n",
    "\n",
    "        observations, rewards, done, info = env.step(actionToTake)\n",
    "\n",
    "        env.render()\n",
    "        \n",
    "    m_dynamics = gympy.generateModel(inputsNumpy, observationsNumpy, k_dynamics)\n",
    "    m_dynamics.optimize()\n",
    "    \n",
    "    \n",
    "    initialX = np.reshape(policyParameters, ([4,1]))\n",
    "#     print initialX\n",
    "    myBopt = GPyOpt.methods.BayesianOptimization(f = objectiveFunction, domain = bounds, acquisition_type ='MPI', num_cores=4)\n",
    "    max_iter = 200              # evaluation budget\n",
    "    myBopt.run_optimization(max_iter)   # run optimization\n",
    "    print myBopt.Y.shape\n",
    "    print min(myBopt.Y)\n",
    "    \n",
    "    policyParameters = myBopt.X[np.argmin(myBopt.Y)]\n",
    "    policyParameters = np.reshape(policyParameters, ([1,4])) \n",
    "    print policyParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.526726   -0.6232747   0.16699651  1.18831694]]\n",
      "[ 1.98033731] [[ 0.  0.  0.]]\n",
      "[ 1.96725037] [[ -2.08143453e-04   1.50854460e-02   3.01740500e-01]]\n",
      "[ 1.95459421] [[-0.0013312   0.04570526  0.61283204]]\n",
      "[ 1.94375552] [[-0.00489984  0.0928154   0.94499002]]\n",
      "[ 1.93593809] [[-0.01352502  0.1577763   1.3108548 ]]\n",
      "[ 1.93232014] [[-0.03131281  0.24210743  1.72426765]]\n",
      "[ 1.934008] [[-0.06443877  0.34696311  2.20038615]]\n",
      "[ 1.9416866] [[-0.1218121   0.4720985   2.75539958]]\n",
      "[ 1.95488492] [[-0.21556771  0.61398599  3.40541635]]\n",
      "[ 1.97106614] [[-0.36070374  0.76272358  4.16382849]]\n",
      "[ 1.98554709] [[-0.57246171  0.89775328  5.036221  ]]\n",
      "[ 1.99383561] [[-0.85930526  0.9838026   6.01205792]]\n",
      "[ 1.99430487] [[-1.20994666  0.97145544  7.05367512]]\n",
      "[ 1.98030342] [[-1.57762936  0.81003212  8.        ]]\n",
      "[ 1.96413154] [[-1.87297487  0.48147699  8.        ]]\n",
      "[ 1.85681522] [[-1.99705827  0.07013926  8.        ]]\n",
      "[ 1.57380823] [[-1.94262706 -0.3400456   8.        ]]\n",
      "[ 1.11057574] [[-1.73871178 -0.68025322  7.98572693]]\n",
      "[ 0.67320403] [[-1.43390608 -0.9072019   7.64681328]]\n",
      "[ 0.40106797] [[-1.09507786 -1.00172118  7.07208237]]\n",
      "[ 0.32292995] [[-0.77780926 -0.98126088  6.38564159]]\n",
      "[ 0.39725241] [[-0.51251726 -0.87939674  5.70282532]]\n",
      "[ 0.56406606] [[-0.30776108 -0.72794035  5.10755553]]\n",
      "[ 0.77131257] [[-0.16007727 -0.54898947  4.65090008]]\n",
      "[ 0.98408336] [[-0.06258248 -0.35451324  4.35954476]]\n",
      "[ 1.18444604] [[-0.01024693 -0.14917826  4.24596224]]\n",
      "[ 1.36647808] [[ -2.60058793e-03   6.60891321e-02   4.31643536e+00]]\n",
      "[ 1.52999656] [[-0.04499594  0.29040247  4.57566382]]\n",
      "[ 1.67476893] [[-0.14880285  0.51862459  5.02765507]]\n",
      "[ 1.79622344] [[-0.3296913   0.73584682  5.67252875]]\n",
      "[ 1.8849397] [[-0.60167242  0.91099851  6.49853729]]\n",
      "[ 1.93223564] [[-0.96377772  0.99309126  7.46921703]]\n",
      "[ 1.96876638] [[-1.37944491  0.91895311  8.        ]]\n",
      "[ 1.97898029] [[-1.74374078  0.66219318  8.        ]]\n",
      "[ 1.92778218] [[-1.95759036  0.28181495  8.        ]]\n",
      "[ 1.74146581] [[-1.99114207 -0.13891305  8.        ]]\n",
      "[ 1.35993205] [[-1.85710333 -0.5213652   8.        ]]\n",
      "[ 0.89042881] [[-1.59619305 -0.80907979  7.81765581]]\n",
      "[ 0.52708387] [[-1.26798404 -0.96967112  7.34910019]]\n",
      "[ 0.35372442] [[-0.93606429 -1.00420848  6.70559933]]\n",
      "[ 0.3570904] [[-0.64352692 -0.94056626  6.01019154]]\n",
      "[ 0.48235471] [[-0.4087204  -0.81273418  5.36302031]]\n",
      "[ 0.67201514] [[-0.23298465 -0.64790532  4.83051279]]\n",
      "[ 0.88239966] [[-0.11029773 -0.46283251  4.45007597]]\n",
      "[ 1.08759419] [[-0.03414451 -0.26540749  4.24000144]]\n",
      "[ 1.27644822] [[ -1.31699525e-03  -5.79378938e-02   4.20877486e+00]]\n",
      "[ 1.44675931] [[-0.01378742  0.15934662  4.36147857]]\n",
      "[ 1.5992615] [[-0.07950494  0.38454704  4.70269234]]\n",
      "[ 1.73249747] [[-0.21200651  0.60945538  5.23568175]]\n",
      "[ 1.83979826] [[-0.42740438  0.8135984   5.95733781]]\n",
      "[ 1.91121352] [[-0.73591513  0.95825159  6.84819625]]\n",
      "[ 1.94006132] [[-1.12532799  0.98585969  7.85825687]]\n",
      "[ 1.97916128] [[-1.53990348  0.83546119  8.        ]]\n",
      "[ 1.96852716] [[-1.85038496  0.51987622  8.        ]]\n",
      "[ 1.87446319] [[-1.99284299  0.11301109  8.        ]]\n",
      "[ 1.61166306] [[-1.95561727 -0.30080075  8.        ]]\n",
      "[ 1.15982583] [[-1.7648072  -0.65048922  8.        ]]\n",
      "[ 0.71210617] [[-1.46727883 -0.89035287  7.69079686]]\n",
      "[ 0.42044187] [[-1.12912436 -0.99787907  7.13453804]]\n",
      "[ 0.32395412] [[-0.80799127 -0.98765025  6.45388492]]\n",
      "[ 0.38549115] [[-0.53686231 -0.89254976  5.76643026]]\n",
      "[ 0.54540769] [[-0.32607167 -0.74506777  5.15953151]]\n",
      "[ 0.75026041] [[-0.1729254  -0.56837415  4.68723174]]\n",
      "[ 0.96332553] [[-0.07059023 -0.37535187  4.3781801 ]]\n",
      "[ 1.16514825] [[-0.01368494 -0.17124162  4.24585493]]\n",
      "[ 1.34888417] [[ -1.18551439e-03   4.28250956e-02   4.29688586e+00]]\n",
      "[ 1.51406234] [[-0.03779987  0.26615921  4.53602721]]\n",
      "[ 1.66071543] [[-0.13429169  0.49432943  4.96744587]]\n",
      "[ 1.78486884] [[-0.30605597  0.71379459  5.59199017]]\n",
      "[ 1.87746799] [[-0.56777473  0.89552183  6.39975633]]\n",
      "[ 1.92939751] [[-0.92101082  0.99062382  7.35770781]]\n",
      "[ 1.9639922] [[-1.33411497  0.93627219  8.        ]]\n",
      "[ 1.98023693] [[-1.71086947  0.69705099  8.        ]]\n",
      "[ 1.93804423] [[-1.94313157  0.32611099  8.        ]]\n",
      "[ 1.77055229] [[-1.99609425 -0.09432875  8.        ]]\n",
      "[ 1.40968533] [[-1.87844074 -0.48406856  8.        ]]\n",
      "[ 0.93838757] [[-1.62875453 -0.78384124  7.85309128]]\n",
      "[ 0.55742479] [[-1.30450832 -0.95875663  7.41065839]]\n",
      "[ 0.36295936] [[-0.97043274 -1.00581658  6.77989454]]\n",
      "[ 0.34962502] [[-0.67235869 -0.95106217  6.08466591]]\n",
      "[ 0.46469709] [[-0.43104529 -0.82863559  5.42850294]]\n",
      "[ 0.64986306] [[-0.24917444 -0.66677598  4.88142072]]\n",
      "[ 0.8596018] [[-0.12112545 -0.48334218  4.48350809]]\n",
      "[ 1.06614269] [[-0.04020861 -0.2870343   4.25463163]]\n",
      "[ 1.25700219] [[ -2.74755762e-03  -8.05940500e-02   4.20396721e+00]]\n",
      "[ 1.42931101] [[-0.01010627  0.13569434  4.33676191]]\n",
      "[ 1.58375177] [[-0.06958626  0.36030736  4.65761921]]\n",
      "[ 1.71929772] [[-0.19420622  0.58596963  5.1701024 ]]\n",
      "[ 1.82985683] [[-0.40008259  0.79382339  5.87216419]]\n",
      "[ 1.90553412] [[-0.69869694  0.9472814   6.74670016]]\n",
      "[ 1.93913272] [[-1.0812364   0.99044006  7.74768123]]\n",
      "[ 1.97730612] [[-1.49742386  0.86124322  8.        ]]\n",
      "[ 1.97242851] [[-1.82373964  0.56068664  8.        ]]\n",
      "[ 1.89167494] [[-1.98611271  0.15970811  8.        ]]\n",
      "[ 1.6506204] [[-1.96797628 -0.25721948  8.        ]]\n",
      "[ 1.21674239] [[-1.79202416 -0.61671758  8.        ]]\n",
      "[ 0.7607336] [[-1.50371496 -0.87011173  7.72466307]]\n",
      "[ 0.44861206] [[-1.16755848 -0.99211202  7.19087922]]\n",
      "[ 0.33138031] [[-0.84306523 -0.99386528  6.51877692]]\n",
      "[ 0.37759375] [[-0.56595599 -0.90715429  5.82777491]]\n",
      "[ 0.52849784] [[-0.34860784 -0.76501122  5.20873816]]\n",
      "[ 0.72939282] [[-0.18928484 -0.59172107  4.71894432]]\n",
      "[ 0.94165045] [[-0.08127033 -0.40118576  4.38925234]]\n",
      "[ 1.14412206] [[-0.01879341 -0.19931276  4.23430049]]\n",
      "[ 1.32889179] [[ -1.56727244e-04   1.25224808e-02   4.26112413e+00]]\n",
      "[ 1.49514378] [[-0.02924067  0.23388068  4.47453966]]\n",
      "[ 1.64325962] [[-0.11598213  0.46123687  4.87891165]]\n",
      "[ 1.77009964] [[-0.27531687  0.68284962  5.47601815]]\n",
      "[ 1.86725238] [[-0.52263783  0.87246406  6.25836021]]\n",
      "[ 1.92515723] [[-0.86266195  0.98427374  7.19748601]]\n",
      "[ 1.95562516] [[-1.27027984  0.95652311  8.        ]]\n",
      "[ 1.98107652] [[-1.66272305  0.74259407  8.        ]]\n",
      "[ 1.94986096] [[-1.91971948  0.38627719  8.        ]]\n",
      "[ 1.80683305] [[-1.99964344 -0.03221294  8.        ]]\n",
      "[ 1.47523214] [[-1.90535284 -0.43087165  8.        ]]\n",
      "[ 1.00431893] [[-1.67213498 -0.7466641   7.90282099]]\n",
      "[ 0.60042164] [[-1.35431919 -0.94137034  7.49816066]]\n",
      "[ 0.3765839] [[-1.01784203 -1.00609367  6.88688605]]\n",
      "[ 0.33940129] [[-0.71229223 -0.96397732  6.19349328]]\n",
      "[ 0.43970611] [[-0.4619341  -0.84916846  5.52611039]]\n",
      "[ 0.61830132] [[-0.27149286 -0.6913122   4.95987986]]\n",
      "[ 0.82714148] [[-0.13603466 -0.50983803  4.53883081]]\n",
      "[ 1.03581422] [[-0.04871501 -0.31462646  4.28521342]]\n",
      "[ 1.22987762] [[-0.00528203 -0.10908828  4.20930561]]\n",
      "[ 1.40541667] [[-0.00633741  0.1063235   4.31666095]]\n",
      "[ 1.56290395] [[-0.05836884  0.33044783  4.61190597]]\n",
      "[ 1.70175006] [[-0.17371685  0.55703043  5.09886734]]\n",
      "[ 1.81655529] [[-0.3683828   0.76904314  5.77659258]]\n",
      "[ 1.89758637] [[-0.65512501  0.93240261  6.63054813]]\n",
      "[ 1.93699325] [[-1.02885057  0.99332997  7.61917794]]\n",
      "[ 1.9741965] [[-1.44558088  0.88897875  8.        ]]\n",
      "[ 1.975978] [[-1.78962074  0.60731685  8.        ]]\n",
      "[ 1.90943153] [[-1.97527516  0.21465453  8.        ]]\n",
      "[ 1.69345628] [[-1.98007489 -0.20478501  8.        ]]\n",
      "[ 1.28222647] [[-1.82241676 -0.57511041  8.        ]]\n",
      "[ 0.81864072] [[-1.54582448 -0.84414001  7.76569107]]\n",
      "[ 0.4830299] [[-1.21273434 -0.98335902  7.26007207]]\n",
      "[ 0.34089536] [[-0.88464534 -0.99957984  6.59969719]]\n",
      "[ 0.36836172] [[-0.60056038 -0.92302123  5.90583652]]\n",
      "[ 0.50813272] [[-0.37542677 -0.78723509  5.27351476]]\n",
      "[ 0.7041539] [[-0.20878589 -0.61781773  4.76399825]]\n",
      "[ 0.91553803] [[-0.09416215 -0.42991959  4.41094795]]\n",
      "[ 1.11905364] [[-0.02540157 -0.23029786  4.23052886]]\n",
      "[ 1.30540719] [[ -8.47755984e-05  -2.06976936e-02   4.23035341e+00]]\n",
      "[ 1.47324243] [[-0.02118935  0.19860767  4.41533113]]\n",
      "[ 1.62319421] [[-0.09772294  0.42494442  4.78996315]]\n",
      "[ 1.7529708] [[-0.2440105   0.64835312  5.3568405 ]]\n",
      "[ 1.85495552] [[-0.47593195  0.84543522  6.11074086]]\n",
      "[ 1.91929046] [[-0.8011053   0.97377163  7.0277505 ]]\n",
      "[ 1.9440521] [[-1.20092606  0.9733492   8.        ]]\n",
      "[ 1.98087641] [[-1.60805948  0.7876233   8.        ]]\n",
      "[ 1.9598116] [[-1.89039973  0.44888799  8.        ]]\n",
      "[ 1.84071409] [[-1.9991497   0.03449991  8.        ]]\n",
      "[ 1.54080314] [[-1.93064577 -0.37212484  8.        ]]\n",
      "[ 1.07392561] [[-1.71621481 -0.70411303  7.95671675]]\n",
      "[ 0.64757829] [[-1.40652682 -0.91988335  7.59441072]]\n",
      "[ 0.39224259] [[-1.06828174 -1.00391794  7.00632485]]\n",
      "[ 0.32861616] [[-0.75500815 -0.97578328  6.31691269]]\n",
      "[ 0.41223785] [[-0.49492691 -0.86934122  5.63905755]]\n",
      "[ 0.58330394] [[-0.29519344 -0.71567218  5.05357722]]\n",
      "[ 0.79113118] [[-0.15178278 -0.53593302  4.60900858]]\n",
      "[ 1.00239722] [[-0.05779478 -0.34134449  4.3304184 ]]\n",
      "[ 1.20042329] [[-0.00844829 -0.13611455  4.22945951]]\n",
      "[ 1.38002593] [[ -3.62286903e-03   7.90203187e-02   4.31212700e+00]]\n",
      "[ 1.54129158] [[-0.04903903  0.30311779  4.58308603]]\n",
      "[ 1.68391119] [[-0.15638215  0.53072158  5.04630801]]\n",
      "[ 1.80306995] [[-0.34144715  0.74629838  5.70162578]]\n",
      "[ 1.88924352] [[-0.61790312  0.91787715  6.53649996]]\n",
      "[ 1.93400507] [[-0.98358727  0.99361242  7.51298426]]\n",
      "[ 1.9706179] [[-1.39974072  0.91036652  8.        ]]\n",
      "[ 1.97821784] [[-1.75808925  0.64587488  8.        ]]\n",
      "[ 1.92260853] [[-1.96345824  0.26153506  8.        ]]\n",
      "[ 1.72746834] [[-1.98824308 -0.1590176   8.        ]]\n",
      "[ 1.33674939] [[-1.84692082 -0.5379411   8.        ]]\n",
      "[ 0.86863442] [[-1.58111063 -0.82006382  7.80174649]]\n",
      "[ 0.51354126] [[-1.25128959 -0.97416008  7.32168369]]\n",
      "[ 0.34970611] [[-0.92045783 -1.00308627  6.67278472]]\n",
      "[ 0.36049722] [[-0.63046504 -0.93547781  5.97761585]]\n",
      "[ 0.49025557] [[-0.39860138 -0.80521704  5.33477198]]\n",
      "[ 0.68188987] [[-0.22563473 -0.63901596  4.80908743]]\n",
      "[ 0.89257152] [[-0.10538711 -0.45313435  4.43679884]]\n",
      "[ 1.09721287] [[-0.03144016 -0.25511003  4.23552371]]\n",
      "[ 1.28524456] [[ -8.13739043e-04  -4.70684795e-02   4.21346303e+00]]\n",
      "[ 1.45474069] [[-0.01577275  0.17076433  4.37563825]]\n",
      "[ 1.60642849] [[-0.08457645  0.39628316  4.72661251]]\n",
      "[ 1.73862198] [[-0.22100111  0.62079638  5.26947905]]\n",
      "[ 1.84437318] [[-0.44112208  0.82300992  6.00055954]]\n",
      "[ 1.91373365] [[-0.75446602  0.96313973  6.89916286]]\n",
      "[ 1.94025403] [[-1.14705801  0.98287176  7.91326761]]\n",
      "[ 1.97984126] [[-1.56042338  0.82193984  8.        ]]\n",
      "[ 1.96625705] [[-1.86280281  0.49925404  8.        ]]\n",
      "[ 1.86516217] [[-1.99535042  0.08986449  8.        ]]\n",
      "[ 1.59147481] [[-1.94879766 -0.32207895  8.        ]]\n",
      "[ 1.13120462] [[-1.75084948 -0.66670434  8.        ]]\n",
      "[ 0.68820369] [[-1.44899289 -0.89977871  7.67434234]]\n",
      "[ 0.40683288] [[-1.11004536 -1.00017761  7.10742877]]\n",
      "[ 0.32049302] [[-0.7906774  -0.98410403  6.4230104 ]]\n",
      "[ 0.38943579] [[-0.52253334 -0.88491369  5.73769623]]\n",
      "[ 0.55368274] [[-0.31498111 -0.73479689  5.13711623]]\n",
      "[ 0.76044593] [[-0.16489349 -0.55637117  4.67376088]]\n",
      "[ 0.97393985] [[-0.06540893 -0.36202852  4.37523929]]\n",
      "[ 1.1755237] [[-0.0113621  -0.15669841  4.25449878]]\n",
      "[ 1.35884974] [[ -2.08448770e-03   5.85823672e-02   4.31799344e+00]]\n",
      "[ 1.52357644] [[-0.04271535  0.2829587   4.57044758]]\n",
      "[ 1.66951465] [[-0.14443772  0.511479    5.01589297]]\n",
      "[ 1.79223924] [[-0.32284174  0.7296022   5.65461932]]\n",
      "[ 1.88240298] [[-0.59212877  0.90679499  6.47534676]]\n",
      "[ 1.93118013] [[-0.9520236   0.9925962   7.44249336]]\n",
      "[ 1.96757251] [[-1.36726713  0.92385458  8.        ]]\n",
      "[ 1.97937638] [[-1.73502064  0.67177033  8.        ]]\n",
      "[ 1.93070829] [[-1.95388769  0.29384839  8.        ]]\n",
      "[ 1.74956866] [[-1.99267672 -0.1268936   8.        ]]\n",
      "[ 1.37356931] [[-1.86302365 -0.51138331  8.        ]]\n",
      "[ 0.90340901] [[-1.6050906  -0.80239496  7.82718782]]\n",
      "[ 0.53522138] [[-1.27789704 -0.96685841  7.36559285]]\n",
      "[ 0.35616997] [[-0.94536112 -1.00476045  6.72542215]]\n",
      "[ 0.35506616] [[-0.65131681 -0.94350113  6.02996721]]\n",
      "[ 0.47761414] [[-0.41475388 -0.81712302  5.38029119]]\n",
      "[ 0.66607941] [[-0.23736396 -0.65310411  4.84378095]]\n",
      "[ 0.87628849] [[-0.11322582 -0.46849364  4.45855468]]\n",
      "[ 1.08183006] [[-0.03577188 -0.27139812  4.24331763]]\n",
      "[ 1.2712002] [[ -1.66299424e-03  -6.42382067e-02   4.20673345e+00]]\n",
      "[ 1.44202385] [[-0.01270203  0.15274779  4.35392473]]\n",
      "[ 1.59502998] [[-0.07665815  0.37777274  4.68947905]]\n",
      "[ 1.72888751] [[-0.20692661  0.60289834  5.216753  ]]\n",
      "[ 1.837089] [[-0.41963034  0.80811388  5.93294979]]\n",
      "[ 1.90969181] [[-0.7253608   0.95529973  6.81928845]]\n",
      "[ 1.93987372] [[-1.11289038  0.98735202  7.82690693]]\n",
      "[ 1.97870395] [[-1.52803312  0.84295842  8.        ]]\n",
      "[ 1.96971981] [[-1.843064   0.5315294  8.       ]]\n",
      "[ 1.879539] [[-1.99116687  0.12622127  8.        ]]\n",
      "[ 1.62292334] [[-1.95930422 -0.28856137  8.        ]]\n",
      "[ 1.17604064] [[-1.77263472 -0.64108025  8.        ]]\n",
      "[ 0.7258076] [[-1.47764756 -0.88479412  7.70028581]]\n",
      "[ 0.42831305] [[-1.14000362 -0.99640143  7.15025127]]\n",
      "[ 0.32599448] [[-0.81789244 -0.98953544  6.47188705]]\n",
      "[ 0.38324988] [[-0.54506634 -0.89678852  5.78332455]]\n",
      "[ 0.54065555] [[-0.33242457 -0.75081291  5.17291054]]\n",
      "[ 0.74440359] [[-0.17753272 -0.57509389  4.6955891 ]]\n",
      "[ 0.95723297] [[-0.07358237 -0.38279882  4.38061912]]\n",
      "[ 1.15921674] [[-0.01507595 -0.17935179  4.24179486]]\n",
      "[ 1.34321673] [[ -7.93100636e-04   3.40536660e-02   4.28585343e+00]]\n",
      "[ 1.50867556] [[-0.03520191  0.25681022  4.51756609]]\n",
      "[ 1.6557377] [[-0.12882926  0.48476167  4.941165  ]]\n",
      "[ 1.78067503] [[-0.29694801  0.70490458  5.5577868 ]]\n",
      "[ 1.87460912] [[-0.55447404  0.88902555  6.3582564 ]]\n",
      "[ 1.92827969] [[-0.90393426  0.98912367  7.31090683]]\n",
      "[ 1.96177613] [[-1.31562855  0.94262312  8.        ]]\n",
      "[ 1.98058646] [[-1.69714573  0.71065723  8.        ]]\n",
      "[ 1.94176163] [[-1.93671233  0.34379448  8.        ]]\n",
      "[ 1.78159874] [[-1.99752669 -0.07626388  8.        ]]\n",
      "[ 1.42919859] [[-1.88660355 -0.46874589  8.        ]]\n",
      "[ 0.95767024] [[-1.6416064  -0.77327089  7.86751027]]\n",
      "[ 0.56984123] [[-1.31911994 -0.95396096  7.43589754]]\n",
      "[ 0.3668296] [[-0.9842728  -1.00612983  6.81059291]]\n",
      "[ 0.34663188] [[-0.68399629 -0.95501767  6.11570988]]\n",
      "[ 0.4574802] [[-0.44005124 -0.83479366  5.45613132]]\n",
      "[ 0.64077469] [[-0.25569269 -0.67411227  4.90334801]]\n",
      "[ 0.85025365] [[-0.1254842  -0.49128549  4.49856991]]\n",
      "[ 1.05738483] [[-0.04268063 -0.29535017  4.26233375]]\n",
      "[ 1.24912731] [[ -3.42939602e-03  -8.92351289e-02   4.20411874e+00]]\n",
      "[ 1.4223214] [[-0.00886306  0.12673674  4.3292514 ]]\n",
      "[ 1.57760449] [[-0.06603607  0.35116518  4.64234206]]\n",
      "[ 1.71409574] [[-0.1877639   0.57710284  5.14704652]]\n",
      "[ 1.82591858] [[-0.39014108  0.78627184  5.84167792]]\n",
      "[ 1.90321772] [[-0.68507227  0.94286894  6.70995949]]\n",
      "[ 1.93859615] [[-1.06493895  0.99163476  7.70728375]]\n",
      "[ 1.97644931] [[-1.48144834  0.87021053  8.        ]]\n",
      "[ 1.97365145] [[-1.81340729  0.57541403  8.        ]]\n",
      "[ 1.8975011] [[-1.98307051  0.17686949  8.        ]]\n",
      "[ 1.66434624] [[-1.97204208 -0.24097896  8.        ]]\n",
      "[ 1.23737213] [[-1.8017077  -0.60394327  8.        ]]\n",
      "[ 0.77873988] [[-1.51695486 -0.86225406  7.73733827]]\n",
      "[ 0.45921105] [[-1.18167083 -0.98960899  7.21214861]]\n",
      "[ 0.33426059] [[-0.85601198 -0.99583548  6.54351343]]\n",
      "[ 0.37470572] [[-0.57671748 -0.91226008  5.85146581]]\n",
      "[ 0.52219744] [[-0.35694742 -0.77209165  5.22816651]]\n",
      "[ 0.7215978] [[-0.19534694 -0.60002498  4.7321173 ]]\n",
      "[ 0.93357503] [[-0.0852625  -0.4103461   4.39502814]]\n",
      "[ 1.13634045] [[-0.0207949  -0.20922036  4.23199472]]\n",
      "[ 1.32156146] [[ -1.34465564e-05   1.87052447e-03   4.25022042e+00]]\n",
      "[ 1.48826857] [[-0.02650846  0.22255301  4.45454743]]\n",
      "[ 1.63694007] [[-0.10992102  0.44959131  4.84939238]]\n",
      "[ 1.76471705] [[-0.26500215  0.67183742  5.43681677]]\n",
      "[ 1.8634346] [[-0.50733241  0.86397545  6.2100923 ]]\n",
      "[ 1.92341435] [[-0.8426211   0.9812882   7.14227898]]\n",
      "[ 1.95219476] [[-1.24792332  0.96252145  8.        ]]\n",
      "[ 1.98113487] [[-1.64536511  0.75760453  8.        ]]\n",
      "[ 1.95336757] [[-1.91070291  0.40676567  8.        ]]\n",
      "[ 1.81835091] [[-1.99997089 -0.01062526  8.        ]]\n",
      "[ 1.49699408] [[-1.91394569 -0.41204569  8.        ]]\n",
      "[ 1.0269827] [[-1.68668092 -0.73319368  7.92020475]]\n",
      "[ 0.61556795] [[-1.37135406 -0.93473672  7.52904679]]\n",
      "[ 0.38153167] [[-1.03421079 -1.00566717  6.92501935]]\n",
      "[ 0.33589052] [[-0.72612698 -0.96802463  6.23268862]]\n",
      "[ 0.43089506] [[-0.47262537 -0.8558982   5.56174363]]\n",
      "[ 0.6071114] [[-0.27919016 -0.6994064   4.98914414]]\n",
      "[ 0.81563185] [[-0.14116182 -0.51853298  4.56034595]]\n",
      "[ 1.02511073] [[-0.05166545 -0.32358374  4.2984809 ]]\n",
      "[ 1.22039764] [[-0.00626835 -0.11821865  4.21424961]]\n",
      "[ 1.39718346] [[-0.00532829  0.09702833  4.31333517]]\n",
      "[ 1.55583321] [[-0.05507305  0.32108456  4.60037384]]\n",
      "[ 1.6958686] [[-0.16762228  0.5479849   5.07925214]]\n",
      "[ 1.81209759] [[-0.35891673  0.76123446  5.74931101]]\n",
      "[ 1.89485397] [[-0.64205391  0.92749655  6.5967414 ]]\n",
      "[ 1.93608631] [[-1.01299781  0.99366207  7.5812818 ]]\n",
      "[ 1.97304269] [[-1.42962516  0.89674481  8.        ]]\n",
      "[ 1.97684439] [[-1.77878612  0.62101207  8.        ]]\n",
      "[ 1.91426622] [[-1.97139254  0.23114637  8.        ]]\n",
      "[ 1.70568576] [[-1.98317847 -0.18879539  8.        ]]\n",
      "[ 1.3015523] [[-1.83118877 -0.56221429  8.        ]]\n",
      "[ 0.83616608] [[-1.55830463 -0.83587607  7.77826203]]\n",
      "[ 0.49363959] [[-1.2262936  -0.9803078   7.28146979]]\n",
      "[ 0.34392033] [[-0.89720447 -1.00095773  6.62497478]]\n",
      "[ 0.36559566] [[-0.61103696 -0.92751482  5.93053443]]\n",
      "[ 0.50190166] [[-0.38354642 -0.79365976  5.29442757]]\n",
      "[ 0.69640589] [[-0.21469083 -0.6253818   4.7791579 ]]\n",
      "[ 0.90753958] [[-0.09808945 -0.43821688  4.41927234]]\n",
      "[ 1.11142674] [[-0.02748879 -0.23919092  4.23143052]]\n",
      "[ 1.29833566] [[ -2.66646004e-04  -3.01762698e-02   4.22344124e+00]]\n",
      "[ 1.46672087] [[-0.01914401  0.18857973  4.40024929]]\n",
      "[ 1.61726222] [[-0.09286034  0.41461864  4.76638212]]\n",
      "[ 1.74789344] [[-0.2355491   0.63845193  5.32462534]]\n",
      "[ 1.85123581] [[-0.4631786   0.83745514  6.07033821]]\n",
      "[ 1.91738439] [[-0.78409196  0.97016482  6.98080484]]\n",
      "[ 1.94027448] [[-1.18140477  0.9771517   8.        ]]\n",
      "[ 1.98061797] [[-1.59224331  0.79949161  8.        ]]\n",
      "[ 1.96215162] [[-1.88143552  0.46601468  8.        ]]\n",
      "[ 1.84930539] [[-1.99821467  0.05314753  8.        ]]\n",
      "[ 1.55824717] [[-1.93704809 -0.35540108  8.        ]]\n",
      "[ 1.09314972] [[-1.72807694 -0.69172786  7.97187617]]\n",
      "[ 0.66094784] [[-1.42089544 -0.91335329  7.62174264]]\n",
      "[ 0.39681897] [[-1.08231295 -1.00285812  7.04055975]]\n",
      "[ 0.32563455] [[-0.76693748 -0.97871964  6.35262891]]\n",
      "[ 0.40442598] [[-0.50413175 -0.87466214  5.67212426]]\n",
      "[ 0.57328845] [[-0.30177627 -0.72215189  5.08148146]]\n",
      "[ 0.78081615] [[-0.15613306 -0.54283646  4.63055072]]\n",
      "[ 0.99285953] [[-0.06030672 -0.34832524  4.3452357 ]]\n",
      "[ 1.1920891] [[-0.00938316 -0.14306334  4.2376106 ]]\n",
      "[ 1.3729401] [[ -3.05609330e-03   7.21166235e-02   4.31381637e+00]]\n",
      "[ 1.53536334] [[-0.04684999  0.29630642  4.57853475]]\n",
      "[ 1.67909591] [[-0.15228207  0.52422532  5.03575898]]\n",
      "[ 1.79945622] [[-0.33508245  0.74068096  5.68548225]]\n",
      "[ 1.88697579] [[-0.6091099   0.91419246  6.51560131]]\n",
      "[ 1.93308997] [[-0.97285568  0.99337885  7.48898192]]\n",
      "[ 1.9696372] [[-1.38875891  0.91507806  8.        ]]\n",
      "[ 1.97864666] [[-1.75035437  0.65476039  8.        ]]\n",
      "[ 1.92545511] [[-1.9603306   0.27254348  8.        ]]\n",
      "[ 1.73511986] [[-1.98986509 -0.14812779  8.        ]]\n",
      "[ 1.34936439] [[-1.85247988 -0.52898136  8.        ]]\n",
      "[ 0.88045235] [[-1.58931136 -0.81414496  7.81035854]]\n",
      "[ 0.52086608] [[-1.26035008 -0.97176222  7.33650758]]\n",
      "[ 0.35187144] [[-0.92892012 -1.00372522  6.69050573]]\n",
      "[ 0.35864854] [[-0.63754527 -0.93826219  5.99518244]]\n",
      "[ 0.48598022] [[-0.40408676 -0.80931653  5.34997298]]\n",
      "[ 0.67654918] [[-0.22961975 -0.64386154  4.82057252]]\n",
      "[ 0.88706923] [[-0.10804888 -0.45842362  4.44384864]]\n",
      "[ 1.09200592] [[-0.03290195 -0.26073147  4.23778122]]\n",
      "[ 1.28047666] [[ -1.07405890e-03  -5.30081484e-02   4.21072341e+00]]\n",
      "[ 1.45040766] [[-0.0146701   0.16452009  4.3677287 ]]\n",
      "[ 1.60253228] [[-0.08177996  0.38986277  4.71336982]]\n",
      "[ 1.73529113] [[-0.21604998  0.61459542  5.25083665]]\n",
      "[ 1.84188869] [[-0.43357864  0.81787602  5.97676678]]\n",
      "[ 1.91237304] [[-0.74427642  0.96050191  6.87114701]]\n",
      "[ 1.94016944] [[-1.13514307  0.98457022  7.8830693 ]]\n",
      "[ 1.97948691] [[-1.54920682  0.82942041  8.        ]]\n",
      "[ 1.96753186] [[-1.85605284  0.51060274  8.        ]]\n",
      "[ 1.87033119] [[-1.99404195  0.1025665   8.        ]]\n",
      "[ 1.60262575] [[-1.95259652 -0.31042852  8.        ]]\n",
      "[ 1.14694366] [[-1.75854715 -0.65784861  8.        ]]\n",
      "[ 0.70130393] [[-1.45904624 -0.89465548  7.683345  ]]\n",
      "[ 0.41427236] [[-1.12051805 -0.99896197  7.12223888]]\n",
      "[ 0.32237442] [[-0.8001734  -0.98608847  6.43984817]]\n",
      "[ 0.38726814] [[-0.53038952 -0.88913732  5.75332788]]\n",
      "[ 0.54914937] [[-0.32106084 -0.74046582  5.14925502]]\n",
      "[ 0.75486796] [[-0.16929455 -0.56299456  4.68096796]]\n",
      "[ 0.96812399] [[-0.06824221 -0.36938383  4.37664214]]\n",
      "[ 1.16983207] [[-0.01261811 -0.16473225  4.24951277]]\n",
      "[ 1.35337477] [[ -1.55680328e-03   4.98736571e-02   4.30612830e+00]]\n",
      "[ 1.51834307] [[-0.0399591   0.27367359  4.55122966]]\n",
      "[ 1.6646737] [[-0.13877729  0.50200767  4.98892622]]\n",
      "[ 1.78819161] [[-0.3134976   0.72089279  5.61982292]]\n",
      "[ 1.8797074] [[-0.57859684  0.90062929  6.43341116]]\n",
      "[ 1.9302308] [[-0.93483262  0.99162242  7.39552914]]\n",
      "[ 1.96565618] [[-1.3489577   0.93087799  8.        ]]\n",
      "[ 1.97988985] [[-1.72175608  0.68587391  8.        ]]\n",
      "[ 1.93486997] [[-1.94806837  0.31175512  8.        ]]\n",
      "[ 1.76134805] [[-1.99470028 -0.10888101  8.        ]]\n",
      "[ 1.39369602] [[-1.87166337 -0.49632349  8.        ]]\n",
      "[ 0.92279114] [[-1.61825923 -0.79221207  7.84150169]]\n",
      "[ 0.54747443] [[-1.29266038 -0.96246367  7.39045121]]\n",
      "[ 0.35989576] [[-0.95924929 -1.00542335  6.75541452]]\n",
      "[ 0.35204898] [[-0.66296651 -0.94775286  6.06002128]]\n",
      "[ 0.47048328] [[-0.42377468 -0.82355786  5.40670388]]\n",
      "[ 0.65713503] [[-0.24390643 -0.66073932  4.86429788]]\n",
      "[ 0.86708333] [[-0.11760174 -0.47679312  4.47200355]]\n",
      "[ 1.07316717] [[-0.03822193 -0.28015199  4.24916111]]\n",
      "[ 1.26334476] [[ -2.23811723e-03  -7.34115275e-02   4.20471209e+00]]\n",
      "[ 1.4349724] [[-0.01120688  0.14316846  4.34384507]]\n",
      "[ 1.58875915] [[-0.07263514  0.36795352  4.67115717]]\n",
      "[ 1.72354896] [[-0.19970837  0.59338385  5.19012609]]\n",
      "[ 1.83306833] [[-0.40855173  0.80010408  5.89838623]]\n",
      "[ 1.90739665] [[-0.71027049  0.95086128  6.77811444]]\n",
      "[ 1.93950281] [[-1.09501601  0.98922067  7.78205981]]\n",
      "[ 1.97795682] [[-1.51081797  0.85342408  8.        ]]\n",
      "[ 1.97130517] [[-1.83227339  0.54808284  8.        ]]\n",
      "[ 1.88652742] [[-1.98845179  0.14515488  8.        ]]\n",
      "[ 1.63873224] [[-1.96432679 -0.27089662  8.        ]]\n",
      "[ 1.1991253] [[-1.78367759 -0.62739633  8.        ]]\n",
      "[ 0.74552083] [[-1.49242414 -0.87659751  7.71401145]]\n",
      "[ 0.43972864] [[-1.15558674 -0.99407236  7.17308134]]\n",
      "[ 0.32900181] [[-0.83211142 -0.99206251  6.49817627]]\n",
      "[ 0.38004797] [[-0.55686039 -0.90271548  5.80816956]]\n",
      "[ 0.53380241] [[-0.34156043 -0.75890391  5.19283005]]\n",
      "[ 0.73594711] [[-0.18416478 -0.58456523  4.70841239]]\n",
      "[ 0.94844895] [[-0.07791185 -0.3932797   4.38507044]]\n",
      "[ 1.1506946] [[-0.01714574 -0.19074149  4.23706791]]\n",
      "[ 1.33511196] [[ -3.72817996e-04   2.17572397e-02   4.27130588e+00]]\n",
      "[ 1.50100432] [[-0.03172533  0.24371085  4.49258051]]\n",
      "[ 1.64865823] [[-0.12139463  0.47133129  4.9052042 ]]\n",
      "[ 1.77468481] [[-0.28446727  0.69234603  5.51069131]]\n",
      "[ 1.87046672] [[-0.53614802  0.87966975  6.30084345]]\n",
      "[ 1.92656221] [[-0.88024495  0.98655262  7.24585567]]\n",
      "[ 1.95838962] [[-1.28971431  0.95085405  8.        ]]\n",
      "[ 1.98092866] [[-1.67760537  0.72915448  8.        ]]\n",
      "[ 1.94655902] [[-1.92721639  0.36822445  8.        ]]\n",
      "[ 1.79633379] [[-1.99897671 -0.05104694  8.        ]]\n",
      "[ 1.4558185] [[-1.89753654 -0.44715349  8.        ]]\n",
      "[ 0.98443955] [[-1.65922225 -0.75818422  7.88769756]]\n",
      "[ 0.58729385] [[-1.33934306 -0.94690884  7.47141523]]\n",
      "[ 0.3723579] [[-1.00351878 -1.00624694  6.85401759]]\n",
      "[ 0.3424814] [[-0.70020672 -0.96026354  6.15987597]]\n",
      "[ 0.44733764] [[-0.4525903  -0.84313075  5.49574043]]\n",
      "[ 0.62796656] [[-0.26475337 -0.68407409  4.93518291]]\n",
      "[ 0.83708145] [[-0.13153792 -0.50204305  4.52101224]]\n",
      "[ 1.04507777] [[-0.04613574 -0.30655352  4.27473207]]\n",
      "[ 1.23811988] [[-0.00446058 -0.10080581  4.2062685 ]]\n",
      "[ 1.41262381] [[-0.00733548  0.11480866  4.32107203]]\n",
      "[ 1.56914181] [[-0.06148436  0.33903667  4.623762  ]]\n",
      "[ 1.70697075] [[-0.179447    0.56534531  5.11810068]]\n",
      "[ 1.82051563] [[-0.37727047  0.77619953  5.80284518]]\n",
      "[ 1.89998771] [[-0.66737659  0.93681343  6.66276208]]\n",
      "[ 1.93772397] [[-1.04365628  0.99279255  7.65506021]]\n",
      "[ 1.97518193] [[-1.46037524  0.88146107  8.        ]]\n",
      "[ 1.97508477] [[-1.79952891  0.59434838  8.        ]]\n",
      "[ 1.90469511] [[-1.97864927  0.19919103  8.        ]]\n",
      "[ 1.68172708] [[-1.97694153 -0.21967075  8.        ]]\n",
      "[ 1.26396564] [[-1.81404389 -0.58702917  8.        ]]\n",
      "[ 0.80226889] [[-1.53405617 -0.85168985  7.75401287]]\n",
      "[ 0.47320069] [[-1.200022   -0.98604062  7.24027572]]\n",
      "[ 0.33813081] [[-0.87290454 -0.9981462   6.57641526]]\n",
      "[ 0.37095631] [[-0.59077674 -0.91869626  5.88321514]]\n",
      "[ 0.5139227] [[-0.36784387 -0.78111019  5.2545263 ]]\n",
      "[ 0.71134233] [[-0.20327084 -0.61061552  4.75047196]]\n",
      "[ 0.92296559] [[-0.0905027  -0.4220058   4.40390158]]\n",
      "[ 1.12615711] [[-0.02348517 -0.22179199  4.23053197]]\n",
      "[ 1.31202382] [[  5.22166366e-06  -1.16066537e-02   4.23780145e+00]]\n",
      "[ 1.47937571] [[-0.02325563  0.20824302  4.43058994]]\n",
      "[ 1.62879272] [[-0.10253151  0.43486515  4.81336846]]\n",
      "[ 1.75775952] [[-0.25232431  0.65783286  5.38852614]]\n",
      "[ 1.85843497] [[-0.48840886  0.85298745  6.15025462]]\n",
      "[ 1.92102199] [[-0.81766552  0.97698698  7.07345035]]\n",
      "[ 1.94747629] [[-1.21978231  0.96929133  8.        ]]\n",
      "[ 1.98104177] [[-1.62315898  0.77582641  8.        ]]\n",
      "[ 1.95736923] [[-1.89876373  0.43214002  8.        ]]\n",
      "[ 1.83203333] [[-1.99972304  0.01643501  8.        ]]\n",
      "[ 1.52353702] [[-1.92416514 -0.38819909  8.        ]]\n",
      "[ 1.05520406] [[-1.7045326  -0.71590542  7.94207114]]\n",
      "[ 0.63470608] [[-1.39251549 -0.92599026  7.56811259]]\n",
      "[ 0.38789384] [[-1.05466361 -1.00475696  6.97351571]]\n",
      "[ 0.33151812] [[-0.74345016 -0.9727894   6.28282197]]\n",
      "[ 0.41974748] [[-0.48600484 -0.864058    5.60764754]]\n",
      "[ 0.5929054] [[-0.28880007 -0.70926278  5.02725607]]\n",
      "[ 0.80101496] [[-0.14754677 -0.52908857  4.58893469]]\n",
      "[ 1.01154933] [[-0.05534868 -0.33438553  4.31696041]]\n",
      "[ 1.20844941] [[-0.00755949 -0.12913788  4.22259357]]\n",
      "[ 1.38688993] [[ -4.24525935e-03   8.60042235e-02   4.31169748e+00]]\n",
      "[ 1.54707742] [[-0.05132386  0.31005468  4.58892404]]\n",
      "[ 1.68864502] [[-0.16064995  0.53736828  5.05821656]]\n",
      "[ 1.80663622] [[-0.34807917  0.75205064  5.71922943]]\n",
      "[ 1.89147044] [[-0.62707221  0.92161502  6.55895275]]\n",
      "[ 1.93486387] [[-0.99476781  0.99373321  7.53857448]]\n",
      "[ 1.97158439] [[-1.41114118  0.90530966  8.        ]]\n",
      "[ 1.97773052] [[-1.76604604  0.6365092   8.        ]]\n",
      "[ 1.9195315] [[-1.96658546  0.25001765  8.        ]]\n",
      "[ 1.71932704] [[-1.98642435 -0.17035206  8.        ]]\n",
      "[ 1.32347355] [[-1.84102469 -0.54721954  8.        ]]\n",
      "[ 0.85630206] [[-1.57249611 -0.82614699  7.79279628]]\n",
      "[ 0.50594399] [[-1.24181375 -0.97657101  7.30632125]]\n",
      "[ 0.3474805] [[-0.91162688 -1.00234238  6.65447449]]\n",
      "[ 0.36243015] [[-0.6230821  -0.93250783  5.95952968]]\n",
      "[ 0.49469569] [[-0.39288075 -0.80087888  5.31920324]]\n",
      "[ 0.68742962] [[-0.22147724 -0.63389382  4.79743834]]\n",
      "[ 0.89828141] [[-0.10261237 -0.44753603  4.42982232]]\n",
      "[ 1.10262634] [[-0.02992749 -0.24914673  4.23360241]]\n",
      "[ 1.29021719] [[ -5.75731334e-04  -4.07526431e-02   4.21682621e+00]]\n",
      "[ 1.45927704] [[-0.01699235  0.17741606  4.38448421]]\n",
      "[ 1.61052049] [[-0.08761644  0.40312671  4.74112772]]\n",
      "[ 1.74212277] [[-0.22636004  0.62739611  5.28974072]]\n",
      "[ 1.84697417] [[-0.4492658   0.82844038  6.02629613]]\n"
     ]
    }
   ],
   "source": [
    "observations = env.reset(whichVersion = 1)\n",
    "predictionPDF = np.reshape(observations, ([1,3]))\n",
    "print policyParameters\n",
    "\n",
    "# policyParameters = np.array([ 0.00875598,  0.25458643, -0.95027489,  6.63289069])\n",
    "# policyParameters = np.reshape(policyParameters, ([1,4]))\n",
    "# observations = env.state(inputTheta = initialStates[0,0], inputThetaDot = initialStates[0.1])\n",
    "for i in range (500):\n",
    "    env.render()\n",
    "    observations = np.reshape(observations, ([1,3]))\n",
    "    action = action_fromPolicy(policyParameters, observations)\n",
    "    action = np.array([action])\n",
    "    \n",
    "    bufferActionToTake = np.reshape(action, ([1,1]))\n",
    "    bufferInputs_policy = np.append(bufferActionToTake, predictionPDF, axis = 1) \n",
    "    \n",
    "    print action, observations-predictionPDF\n",
    "    \n",
    "#     predictionPDF = m_dynamics.predict(bufferInputs_policy)[0]\n",
    "    observations, rewards, done, info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
